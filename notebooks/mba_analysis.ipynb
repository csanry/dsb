{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl \n",
    "# import missingno as msno\n",
    "import seaborn as sns\n",
    "\n",
    "from src import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 112650 entries, 0 to 112649\n",
      "Data columns (total 7 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   order_id             112650 non-null  object \n",
      " 1   order_item_id        112650 non-null  int64  \n",
      " 2   product_id           112650 non-null  object \n",
      " 3   seller_id            112650 non-null  object \n",
      " 4   shipping_limit_date  112650 non-null  object \n",
      " 5   price                112650 non-null  float64\n",
      " 6   freight_value        112650 non-null  float64\n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 6.0+ MB\n",
      "order_id               0\n",
      "order_item_id          0\n",
      "product_id             0\n",
      "seller_id              0\n",
      "shipping_limit_date    0\n",
      "price                  0\n",
      "freight_value          0\n",
      "dtype: int64\n",
      "\n",
      "None\n",
      "None\n",
      "(112650, 7)\n",
      "                           order_id  order_item_id  \\\n",
      "0  00010242fe8c5a6d1ba2dd792cb16214              1   \n",
      "1  00018f77f2f0320c557190d7a144bdd3              1   \n",
      "2  000229ec398224ef6ca0657da4fc703e              1   \n",
      "3  00024acbcdf0a6daa1e931b038114c75              1   \n",
      "4  00042b26cf59d7ce69dfabb4e55b4fd9              1   \n",
      "\n",
      "                         product_id                         seller_id  \\\n",
      "0  4244733e06e7ecb4970a6e2683c13e61  48436dade18ac8b2bce089ec2a041202   \n",
      "1  e5f2d52b802189ee658865ca93d83a8f  dd7ddc04e1b6c2c614352b383efe2d36   \n",
      "2  c777355d18b72b67abbeef9df44fd0fd  5b51032eddd242adc84c38acab88f23d   \n",
      "3  7634da152a4610f1595efa32f14722fc  9d7a1d34a5052409006425275ba1c2b4   \n",
      "4  ac6c3623068f30de03045865e4e10089  df560393f3a51e74553ab94004ba5c87   \n",
      "\n",
      "   shipping_limit_date   price  freight_value  \n",
      "0  2017-09-19 09:45:35   58.90          13.29  \n",
      "1  2017-05-03 11:05:13  239.90          19.93  \n",
      "2  2018-01-18 14:48:30  199.00          17.87  \n",
      "3  2018-08-15 10:10:18   12.99          12.79  \n",
      "4  2017-02-13 13:57:51  199.90          18.14  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(config.RAW_FILE_PATH / 'olist_order_items_dataset.csv')\n",
    "\n",
    "print(f'''\n",
    "{df.info()}\n",
    "{print(df.isna().sum())}\n",
    "{df.shape}\n",
    "{df.head()}\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby('order_id').agg({'product_id': lambda x: list(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s s eta 0:00:01  |▎                               | 2.7 MB 5.0 MB/s eta 0:00:56     |█                               | 8.1 MB 5.0 MB/s eta 0:00:55     |█▏                              | 9.9 MB 5.0 MB/s eta 0:00:54     |██                              | 17.1 MB 13.6 MB/s eta 0:00:20     |██▏                             | 19.3 MB 13.6 MB/s eta 0:00:20     |████▊                           | 41.9 MB 15.9 MB/s eta 0:00:16     |██████▏                         | 54.3 MB 15.9 MB/s eta 0:00:15     |███████████▋                    | 101.7 MB 14.1 MB/s eta 0:00:13     |███████████▊                    | 102.6 MB 14.1 MB/s eta 0:00:13     |████████████▎                   | 108.3 MB 14.1 MB/s eta 0:00:13     |█████████████                   | 114.8 MB 14.1 MB/s eta 0:00:12     |██████████████                  | 123.2 MB 17.3 MB/s eta 0:00:10     |█████████████████▊              | 156.1 MB 14.3 MB/s eta 0:00:09     |██████████████████▉             | 165.3 MB 13.9 MB/s eta 0:00:09     |█████████████████████           | 184.7 MB 3.1 MB/s eta 0:00:32     |█████████████████████▏          | 185.9 MB 3.1 MB/s eta 0:00:31     |███████████████████████████▎    | 239.8 MB 16.8 MB/s eta 0:00:03\n",
      "\u001b[?25hCollecting py4j==0.10.9.3\n",
      "  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n",
      "\u001b[K     |████████████████████████████████| 198 kB 7.2 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=c9a35aa1fc87ed09bec37c8434be8ee4ff51ec66925d10d1144948791699cdbc\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/45/50/69db7b6e1da74a1b9fcc097827db9185cb8627117de852731e\n",
      "Successfully built pyspark\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Collecting findspark\n",
      "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: findspark\n",
      "Successfully installed findspark-2.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark\n",
    "!pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease                        \n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]      \n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:5 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2830 kB]\n",
      "Get:6 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1515 kB]\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2290 kB]\n",
      "Get:8 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [982 kB]\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1015 kB]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3262 kB]\n",
      "Fetched 12.1 MB in 9s (1353 kB/s)                                              \n",
      "Reading package lists... Done\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n"
     ]
    }
   ],
   "source": [
    "!apt-get update --fix-missing\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as T \n",
    "import pyspark.sql.functions as F \n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SparkSession, SQLContext\n",
    "\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml.fpm import FPGrowth\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import os\n",
    "\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# conf = SparkConf().setAppName(\"base\").setMaster(\"local[*]\")\n",
    "# spark = SparkContext(conf=conf).getOrCreate()\n",
    "# spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.read.options(header='true').csv('../data/raw/olist_order_items_dataset.csv')\n",
    "\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df.dropDuplicates(['order_id', 'product_id']).sort('order_id')\n",
    "\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupBy('order_id').agg(F.collect_list('product_id')).sort('order_id')\n",
    "\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpGrowth = FPGrowth(itemsCol='collect_list(product_id)', minSupport=0.00001, minConfidence=0.0001)\n",
    "\n",
    "model = fpGrowth.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.freqItemsets.show()\n",
    "items = model.freqItemsets.toPandas()\n",
    "\n",
    "model.associationRules.show()\n",
    "rules = model.associationRules.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items.to_csv('./mba_freq_items.csv')\n",
    "rules.to_csv('./mba_pattern.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "44a3c08237e01b3f273f94d4b0b6f4bfc3fd3da5036836380d570cd78e561537"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
